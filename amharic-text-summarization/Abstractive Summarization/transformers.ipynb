{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf9fb96-07eb-44f1-b148-9f96162eb8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98cb0db9-bd45-46c8-a515-feafe1de0347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import time\n",
    "import re\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b84d537-9e20-4ad4-957f-f488460be593",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64\n",
    "default_path = \"/content/drive/MyDrive/amharic_text_summarization/\"\n",
    "test = 12000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b88e428-25c5-46ee-bf65-b249f7907b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(default_path +'content.pickle', 'rb') as handle:\n",
    "    content = pickle.load(handle)\n",
    "with open(default_path +'summary.pickle', 'rb') as handle:\n",
    "    summary = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b452f747-0257-41ca-96fb-ef2eb08bba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "content.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e36c0b7-56f2-4579-8a59-3cb770ad33ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = content[:content.shape[0]-test, :], summary[:summary.shape[0]-test, :]\n",
    "x_test, y_test = content[:-test, :], summary[:-test, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ca4886-6211-4af9-87d1-067a73ee7d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d978456d-a471-4a3d-aad0-cb55a9fd8ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(position, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return position * angle_rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a6da33-5238-48da-b8b0-084caf3a5d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis],\n",
    "        np.arange(d_model)[np.newaxis, :],\n",
    "        d_model\n",
    "    )\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7102409-f1c2-48a9-b1ba-dba67c4efc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed045db8-c9b7-4000-a470-f9c97b03f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4cb2ea-5b5f-485a-9202-6bee4055ae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a381a2-9b8c-4d9a-9ac8-7ff9b318b5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        output = self.dense(concat_attention)\n",
    "            \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7548e59b-748c-4aef-ad4d-ded1bf5ed99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321dc4bd-a526-448a-8cea-321b2c7ba9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696ed23c-e3d4-4207-86e8-1a8e14b077d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b169470-31df-4a11-8355-3675ccd339c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, emb_matrix, max_len, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim = input_vocab_size, \n",
    "                      output_dim = d_model,\n",
    "                      input_length = max_len, # max_len of text sequence - 300\n",
    "                      weights=[emb_matrix],\n",
    "                      trainable=False) # static weights to be assigned from pretrained embedding\n",
    "        #self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "    \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470b43be-6ed8-44ed-a8a4-c2705e6750f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, emb_matrix, max_len, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        #self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim = target_vocab_size, \n",
    "                      output_dim = d_model,\n",
    "                      input_length = max_len, # max_len of summ sequence - 16\n",
    "                      weights=[emb_matrix],\n",
    "                      trainable=False)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4761781-d5fa-46ba-aa26-ca9695f117f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, text_matrix, max_len_text, summ_matrix, max_len_summ, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, text_matrix, max_len_text, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, summ_matrix, max_len_summ, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
    "\n",
    "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0818673-da4c-4420-bf9d-a3a523ed8704",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(default_path +'content_matrix.pickle', 'rb') as handle:\n",
    "    content_matrix = pickle.load(handle)\n",
    "with open(default_path +'summary_matrix.pickle', 'rb') as handle:\n",
    "    summary_matrix = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2904561-7c8a-45d8-8bcd-b73ce57f7d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-params\n",
    "num_layers = 4\n",
    "d_model = content_matrix.shape[1]\n",
    "dff = 512\n",
    "num_heads = 10\n",
    "EPOCHS = 20\n",
    "max_len_text = 300\n",
    "max_len_summ = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c12003-1a5a-4a7a-917e-fc2bb719a7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_vocab_size = 110757\n",
    "decoder_vocab_size = 25121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f403b75b-e5f7-42dc-92ad-af0b3b248d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f263a0-2d82-466b-a665-0b7be5c4d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da7ec6d-689e-483b-8846-269d41ccc08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff57674-e58e-45d7-a92c-1edb276f6172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4050813-0b05-404a-9591-a4ae3658369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91551173-c74d-4baa-be4b-51879f2b9692",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = tf.keras.metrics.Mean(name='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a06132-462d-4446-88aa-8236aed7f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers, \n",
    "    d_model, \n",
    "    num_heads, \n",
    "    dff,\n",
    "    encoder_vocab_size, \n",
    "    decoder_vocab_size, \n",
    "    pe_input = encoder_vocab_size, \n",
    "    pe_target = decoder_vocab_size,\n",
    "    text_matrix = content_matrix, \n",
    "    max_len_text = 400, \n",
    "    summ_matrix = summary_matrix, \n",
    "    max_len_summ = 20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2f2bcf-8c17-4e97-9363-76a5757e6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea3314b-b2af-49f7-b3b6-a98b1afb5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = default_path+\"checkpoints\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea0d62d-5430-4384-a6be-d714efbcf7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(\n",
    "            inp, tar_inp, \n",
    "            True, \n",
    "            enc_padding_mask, \n",
    "            combined_mask, \n",
    "            dec_padding_mask\n",
    "        )\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "        \n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694eae84-374f-497e-8d38-ecf63da98f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def val_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(\n",
    "            inp, tar_inp, \n",
    "            False, \n",
    "            enc_padding_mask, \n",
    "            combined_mask, \n",
    "            dec_padding_mask\n",
    "        )\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "    val_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c5882-f0ed-4440-8486-9834fa04e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    val_loss.reset_states()\n",
    "   \n",
    "    for (batch, (inp, tar)) in enumerate(dataset):\n",
    "        train_step(inp, tar)\n",
    "    \n",
    "        if batch % 2601 == 0:\n",
    "            print ('Epoch {} ========> Batch {} Loss {:.4f}'.format(epoch + 1, batch, train_loss.result().numpy()))\n",
    "      \n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
    "\n",
    "    train_loss_values.append(train_loss.result().numpy())\n",
    "    \n",
    "    #test set - forward pass, loss fn (no backward pass)\n",
    "    for (batch, (inp, tar)) in enumerate(test_dataset):\n",
    "        val_step(inp, tar)\n",
    "\n",
    "    test_loss_values.append(val_loss.result().numpy())\n",
    "    \n",
    "    print ('Epoch {}/{} ========> Training Loss {:.4f} Test/Validation Loss {:.4f}'.format(epoch + 1, EPOCHS, train_loss.result().numpy(), val_loss.result().numpy()))\n",
    "    \n",
    "    print ('Time taken for epoch {}: {:.2f} secs\\n'.format(epoch+1, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de21caa-88e7-4e8d-87df-5aa4d6f70d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_epochs = [i for i in range(EPOCHS)]\n",
    "fig , ax = plt.subplots(1,1)\n",
    "fig.set_size_inches(10,6)\n",
    "ax.plot(no_of_epochs, test_loss_values, label = 'Testing Loss')\n",
    "ax.plot(no_of_epochs, train_loss_values, label = 'Training Loss')\n",
    "ax.set_title('Categorical Crossentropy Loss vs No. of Epochs')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"No. of Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888165ee-f38d-485d-b2d5-0a9f178e1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(default_path +'content_tokenizer.pickle', 'rb') as handle:\n",
    "    content_tokenizer = pickle.load(handle)\n",
    "with open(default_path +'summary_tokenizer.pickle', 'rb') as handle:\n",
    "    summary_tokenizer = pickle.load(handle)\n",
    "max_content_len = 400\n",
    "max_summary_len = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d72d7c-8828-4c71-867a-b1f6590842eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_document):\n",
    "    # #clean\n",
    "    #input_document = preprocess_tokenize(input_document)\n",
    "    input_document = \"sostok \"+ input_document+\" eostok\"\n",
    "    #tokenize\n",
    "    input_document = content_tokenizer.texts_to_sequences([input_document])\n",
    "    #padding\n",
    "    input_document = tf.keras.preprocessing.sequence.pad_sequences(input_document, maxlen=max_content_len, padding='post', truncating='post')\n",
    "\n",
    "    encoder_input = tf.expand_dims(input_document[0], 0)\n",
    "\n",
    "    decoder_input = [summary_tokenizer.word_index[\"sostok\"]]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "    for i in range(max_summary_len):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
    "\n",
    "        predictions, attention_weights = transformer(\n",
    "            encoder_input, \n",
    "            output,\n",
    "            False,\n",
    "            enc_padding_mask,\n",
    "            combined_mask,\n",
    "            dec_padding_mask,\n",
    "        )\n",
    "\n",
    "        predictions = predictions[: ,-1:, :]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        if predicted_id == summary_tokenizer.word_index[\"eostok\"]:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f767f44-076f-4c35-9ad3-267a409574a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(input_document):\n",
    "    # not considering attention weights for now, can be used to plot attention heatmaps in the future\n",
    "    summarized = predict(input_document=input_document)[0].numpy()\n",
    "    summarized = np.expand_dims(summarized[1:], 0)  # not printing <go> token\n",
    "    return summary_tokenizer.sequences_to_texts(summarized)[0]  # since there is just one translated document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b57e3b-7d9d-471c-9310-29033fb8d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(\"የኢትዮጵያ ሰብአዊ መብቶች ኮሚሽን፣ በየዓመቱ የሚያዘጋጀው የፊልም ዐውደ ትርኢት ፣ዘንድሮ ለሦስተኛ ጊዜ፣ በዚኽ ሳምንት ተጀምሯል፡፡ ከትላንት በስቲያ ሰኞ፣ ታኅሣሥ 1 ቀን 2016 ዓ.ም. በዐዲስ አበባ የተጀመረው ሦስተኛው ዙር የፊልም ዐውደ ትርኢት፣ የአጫጭር ፊልም እና የፎቶግራፍ ውድድሮችን ጨምሮ፣ ከ160 በላይ የኪነ ጥበብ ሥራዎችን ያካተተ ነው። በባለሞያዎች ከተዘጋጁት ፊልሞች መካከል፣ የአሕመድ አብዱ ሰዒድ፣ “ለምን” የተሰኘ አጭር ፊልም አሸናፊ ኾኗል፡፡ በጀማሪ ባለሞያዎች ከተሠሩት መሀከል ደግሞ፣ የዐዲሱ ደመቀ ‘‘ስለ ሕይወት’’ ፊልም አሸንፏል፡፡\n",
    "የዘንድሮው፣ የሰብአዊ መብቶች ፊልም ፌስቲቫል፣ በኮሚሽኑ፣ “አሳሳቢ” ተብለው በተለዩት በሕይወት የመኖር እና የመኖሪያ ቤት የማግኘት መብቶች ላይ ትኩረት አድርጓል፡፡ ስለ ፌስቲቫሉ አስተያየት የሰጡት፣ የኢትዮጵያ ሰብአዊ መብቶች ኮሚሽን ዋና ኮሚሽነር ዶር. ዳንኤል በቀለ፣ የፌስቲቫሉ ዓላማ፥ ኪነ ጥበብን በመጠቀም፣ ስለ ሰብአዊ መብቶች ግንዛቤ ለመፍጠር እንደኾነ ገልጸው፣ አካሔዱን ውጤት እያየንበት ነው፤ ብለዋል፡፡\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ebf8f5-d63b-475c-bdd4-59cd0cfe1fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = test[\"content\"]\n",
    "summary = test[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7933bcdf-f162-454f-a794-e329176af12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [17, 35, 69, 21, 26]\n",
    "docs = []\n",
    "summ = []\n",
    "pred = []\n",
    "for i in samples:\n",
    "  pred.append(summarize(documents[i]))\n",
    "  docs.append(' '.join(documents[i].split(' ')[:100]))\n",
    "  summ.append(summary[i])\n",
    "\n",
    "\n",
    "result_df = pd.DataFrame({'Input': docs, 'Reference Summary': summ, 'Model Output Summary': pred, 'Padding':pred })\n",
    "result_df[['Input', 'Reference Summary', 'Model Output Summary']] #17, 69, 21, 26, 35\n",
    "result_df.style.set_properties(subset=['Input', 'Padding'], **{'width': '400px'})\n",
    " \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05864605-7a86-453f-a486-39185120cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fece78-f594-4c97-bf8b-7179ac64f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0454d4c-c57f-4cb7-9d34-362f542bfc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d736772-3387-4910-8a1a-530908935be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = result_df['Model Output Summary'][0]\n",
    "reference = result_df['Reference Summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31f8d8c-20aa-4430-98ea-14adc8e1eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge.get_scores(summary,reference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
