{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b59bb44-9e36-44cf-bbbe-d043f8998d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc755cfe-41dd-4b5c-ae5a-f3e6cf33e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = pd.read_csv('../../cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0b01848-261b-4b3d-aa7e-08cd9703e318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53782</th>\n",
       "      <td>ኦዚ ደርሶ መልስ ኤፍሬም  ማዴቦ  መልሱን እነሆ  አንዱአለም ተፈራ</td>\n",
       "      <td>አንዱአለም ተፈራ አርብ ግንቦት  ቀን  አመተ ምህረት  ኦዚ ደርሶ መልስ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53783</th>\n",
       "      <td>ቴዲ አፍሮ በኢህአዴግ ለምን ይጠላል ወይም እንደ ትልቅ አደጋ ይታያል</td>\n",
       "      <td>ከጌታቸው ስሜ ቴዲ አፍሮ የሚነያሳቸው የኢትዮጵያዊነት ወይም የተለያየ ማህ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53784</th>\n",
       "      <td>ትራምፕ ሙስሊሞችን ከማገድ ወደ ሙስሊም አገር መንጎድ   በሳዲቅ አህመድ ...</td>\n",
       "      <td>በኤፍቢአይ ምርመራ የፖለቲካ አጣብቂኝ ዉስጥ የገቡት ዶናልድ ትራምፕ ከ የ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53785</th>\n",
       "      <td>ከቴዲ አፍሮ ጋር ያደረገው ቃለምልልስ በኢቢሲ የታገደበት ጋዜጠኛ ስራውን ...</td>\n",
       "      <td>ዘሀበሻ ቴዲ አፍሮ መኖሪያ ቤት ድረስ ሄዶ ቃለምልልስ አድርጎ እንዳይተላለ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53786</th>\n",
       "      <td>ራእይአቹ ምንድን ነው   ከተማ ዋቅጅራ</td>\n",
       "      <td>ራእይ የሚያይ ቅን ሰው ራእይ የሚፈታ ቅዱስ አባት ያስፈልጋል። የኢትዮጵያ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "53782         ኦዚ ደርሶ መልስ ኤፍሬም  ማዴቦ  መልሱን እነሆ  አንዱአለም ተፈራ   \n",
       "53783        ቴዲ አፍሮ በኢህአዴግ ለምን ይጠላል ወይም እንደ ትልቅ አደጋ ይታያል   \n",
       "53784  ትራምፕ ሙስሊሞችን ከማገድ ወደ ሙስሊም አገር መንጎድ   በሳዲቅ አህመድ ...   \n",
       "53785  ከቴዲ አፍሮ ጋር ያደረገው ቃለምልልስ በኢቢሲ የታገደበት ጋዜጠኛ ስራውን ...   \n",
       "53786                           ራእይአቹ ምንድን ነው   ከተማ ዋቅጅራ   \n",
       "\n",
       "                                                 content  \n",
       "53782  አንዱአለም ተፈራ አርብ ግንቦት  ቀን  አመተ ምህረት  ኦዚ ደርሶ መልስ ...  \n",
       "53783  ከጌታቸው ስሜ ቴዲ አፍሮ የሚነያሳቸው የኢትዮጵያዊነት ወይም የተለያየ ማህ...  \n",
       "53784  በኤፍቢአይ ምርመራ የፖለቲካ አጣብቂኝ ዉስጥ የገቡት ዶናልድ ትራምፕ ከ የ...  \n",
       "53785  ዘሀበሻ ቴዲ አፍሮ መኖሪያ ቤት ድረስ ሄዶ ቃለምልልስ አድርጎ እንዳይተላለ...  \n",
       "53786  ራእይ የሚያይ ቅን ሰው ራእይ የሚፈታ ቅዱስ አባት ያስፈልጋል። የኢትዮጵያ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36231579-fdf3-4797-a6f7-6c5927dd0f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractiveModel:\n",
    "\n",
    "    am_sent_endings = r'\\?|\\!|\\።|\\፡፡'\n",
    "    am_punctuation = '፠፡።፣፤፥፦፧፨“”‘’…‹‹››·•'\n",
    "    am_numbers = '፩፪፫፬፭፮፯፰፱፲፳፴፵፶፷፸፹፺፻፼'\n",
    "    am_random = '�©\\uf0c4\\uf0d8\\uf0a7\\uf066\\uf0d8'\n",
    "    stop_words = open('stopwords.txt', encoding='utf-8').read().split()\n",
    "\n",
    "    def __init__(self, text):\n",
    "        self.raw_text = text\n",
    "        self.clean_text = None\n",
    "        self.sentences = None\n",
    "        self.words = None\n",
    "\n",
    "        self.process_text()\n",
    "\n",
    "    def process_text(self):\n",
    "        self.clean_text = self.clean_minimized(self.raw_text)\n",
    "        self.sentences = self.extract_sentences(self.clean_text)\n",
    "        self.sentences = self.remove_duplicate_sentence(self.sentences)\n",
    "        self.words = self.extract_words(self.clean_text)\n",
    "\n",
    "    def extract_sentences(self, text=None):\n",
    "        if text is None:\n",
    "            text = self.raw_text\n",
    "        sentences = re.split(self.am_sent_endings, text)\n",
    "        return sentences\n",
    "\n",
    "    def extract_words(self, text):\n",
    "        return text.split()\n",
    "\n",
    "    def clean_minimized(self, text):\n",
    "        words = text.split()\n",
    "        to_clean = string.punctuation + self.am_numbers + self.am_random + string.ascii_letters + string.digits + self.am_punctuation\n",
    "        to_clean = re.sub(self.am_sent_endings, '', to_clean)\n",
    "        table = str.maketrans('', '', to_clean)\n",
    "        stripped = [w.translate(table) for w in words]\n",
    "        clean_txt = list(filter(None, stripped))\n",
    "        return ' '.join(clean_txt)\n",
    "\n",
    "    def remove_duplicate_sentence(self, sentences):\n",
    "        duplicates = []\n",
    "        cleaned = []\n",
    "        for s in sentences:\n",
    "            if s in cleaned:\n",
    "                if s in duplicates:\n",
    "                    continue\n",
    "                else:\n",
    "                    duplicates.append(s)\n",
    "            else:\n",
    "                cleaned.append(s)\n",
    "        return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58c01ff4-3cbb-4fba-b045-d28eef92a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_dictionary_table(words) -> dict:\n",
    "    frequency_table = dict()\n",
    "\n",
    "    for wd in words:\n",
    "        if wd in frequency_table:\n",
    "            frequency_table[wd] += 1\n",
    "        else:\n",
    "            frequency_table[wd] = 1\n",
    "\n",
    "    return frequency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3a51f2d-b213-4b39-ade9-a6b51039c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_sentence_scores(sentences, frequency_table) -> dict:\n",
    "    sentence_weight = dict()\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_wordcount_without_stop_words = 0\n",
    "        words = sentence.split()\n",
    "        for word in words:\n",
    "            if word in frequency_table:\n",
    "                sentence_wordcount_without_stop_words += frequency_table[word]\n",
    "\n",
    "        sentence_weight[sentence] = sentence_wordcount_without_stop_words\n",
    "\n",
    "    return sentence_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6001b7f-9129-4533-b7a1-92c547c7024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_average_score(sentence_weight) -> int:\n",
    "    sum_values = 0\n",
    "    for entry in sentence_weight:\n",
    "        sum_values += sentence_weight[entry]\n",
    "\n",
    "    average_score = (sum_values / len(sentence_weight))\n",
    "\n",
    "    return average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0fc769f-60b5-4cc1-8d77-c4c538a52b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_article_summary(sentences, sentence_weight, threshold):\n",
    "    sentence_counter = 0\n",
    "    article_summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # print(sentence_weight)\n",
    "        if sentence in sentence_weight and sentence_weight[sentence] >= threshold//2:\n",
    "            article_summary += sentence + '።'\n",
    "            sentence_counter += 1\n",
    "\n",
    "    article_summary = re.sub(r'((\\b\\w+\\b.{1,2}\\w+\\b)+).+\\1', r'\\1', article_summary, flags=re.I)\n",
    "\n",
    "    return article_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "840fcae8-0ce6-4c62-908e-f74bc03875bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_summary(tparser, threshold_parameter=1.5):\n",
    "    sentences = tparser.sentences\n",
    "\n",
    "    frequency_table = _create_dictionary_table(tparser.words)\n",
    "\n",
    "    sentence_scores = _calculate_sentence_scores(sentences, frequency_table)\n",
    "\n",
    "    threshold = _calculate_average_score(sentence_scores)\n",
    "\n",
    "    return _get_article_summary(sentences, sentence_scores, threshold_parameter * threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96d79575-5a06-4309-a325-f76119d08c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: etnltk in /home/yohannes/.local/lib/python3.10/site-packages (0.0.22)\n",
      "Requirement already satisfied: emoji>=1.7.0 in /home/yohannes/.local/lib/python3.10/site-packages (from etnltk) (2.9.0)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /home/yohannes/.local/lib/python3.10/site-packages (from etnltk) (0.0.24)\n",
      "Requirement already satisfied: pyahocorasick in /home/yohannes/.local/lib/python3.10/site-packages (from textsearch>=0.0.21->etnltk) (2.0.0)\n",
      "Requirement already satisfied: anyascii in /home/yohannes/.local/lib/python3.10/site-packages (from textsearch>=0.0.21->etnltk) (0.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install etnltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e85104b2-b871-4e68-b9d2-079e4c2c7d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from etnltk.tokenize.am import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4381ad8a-f297-4f50-9197-9a449515fe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def longest_common_subsequence(a, b):\n",
    "    matcher = SequenceMatcher(None, a, b)\n",
    "    match = matcher.find_longest_match(0, len(a), 0, len(b))\n",
    "    return a[match.a: match.a + match.size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b501d44-46ad-48ab-a375-617884a88bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_n(reference, candidate, n=1):\n",
    "    reference_tokens = word_tokenize(reference)\n",
    "    candidate_tokens = word_tokenize(candidate)\n",
    "    \n",
    "    reference_ngrams = set(nltk.ngrams(reference_tokens, n))\n",
    "    candidate_ngrams = set(nltk.ngrams(candidate_tokens, n))\n",
    "    \n",
    "    precision = len(reference_ngrams.intersection(candidate_ngrams))\n",
    "    recall = len(reference_ngrams) + len(candidate_ngrams) - precision\n",
    "    \n",
    "    if recall == 0:\n",
    "        rouge_n_score = 0.0\n",
    "    else:\n",
    "        rouge_n_score = precision / recall\n",
    "    \n",
    "    return rouge_n_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19a74124-5b35-4dea-b39a-310708c0fb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_l(reference, candidate):\n",
    "    reference_tokens = word_tokenize(reference)\n",
    "    candidate_tokens = word_tokenize(candidate)\n",
    "    \n",
    "    reference_ngrams_all = list(nltk.ngrams(reference_tokens, 1))\n",
    "    candidate_ngrams_all = list(nltk.ngrams(candidate_tokens, 1))\n",
    "    \n",
    "    reference_lcs = longest_common_subsequence(reference_ngrams_all, candidate_ngrams_all)\n",
    "    \n",
    "    rouge_l_score = len(reference_lcs) / max(1, len(reference_ngrams_all))\n",
    "    \n",
    "    return rouge_l_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b48cdb1-eadd-4d73-94be-36891282d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rouge_scores(reference, candidate):\n",
    "    rouge_n_1 = rouge_n(reference, candidate, n=1)\n",
    "    rouge_n_2 = rouge_n(reference, candidate, n=2)\n",
    "    rouge_l_score = rouge_l(reference, candidate)\n",
    "    \n",
    "    return rouge_n_1, rouge_n_2, rouge_l_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14928203-7b62-4a27-bdb9-39937b055874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_score(reference_summary, generated_summary):\n",
    "    rouge_n_1, rouge_n_2, rouge_l_score = calculate_rouge_scores(reference_summary, generated_summary)\n",
    "    \n",
    "    print(f\"ROUGE-1: {rouge_n_1:.4f}\")\n",
    "    print(f\"ROUGE-2: {rouge_n_2:.4f}\")\n",
    "    print(f\"ROUGE-L: {rouge_l_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bc79ffa-362b-4505-bbc6-5aef15839313",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_data['content']\n",
    "y = cleaned_data['title']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3f050df-b089-4849-a9c7-6c89767e550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e57a1ad-dc28-46f5-8c1a-690605bedf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.0625\n",
      "ROUGE-2: 0.0323\n",
      "ROUGE-L: 0.4000\n",
      "\n",
      "\n",
      "\n",
      "Text\n",
      "\n",
      "\n",
      "ባለፉት ሶስት አመታት በአደንዛዥ እፅ ሱሰኝነት በቤተሰብ ችግርና በሌሎች የገንዘብ ኪሳራ እክሎች ስትባክን የቆየችው የ አመቷ ሊንድሴይ ሎሀን በፊልሙ ላይ ለመስራት ጉጉት እንዳደረባት ሮይተርስ አውስቷል። ሊዝ ኤንድ ዲክ በሰኔ ወር የፊልሙ ቀረፃ እንደሚጀመር ሲታወቅ ሊንድሴይ ሎሀን በተሳካ ትወና የተዳከመ ዝና እና ገቢዋን በማስመለስ ልታገግምበት እንደምትችል ተገምቷል።ለመጨረሻ ጊዜ ፊልም ከሰራች ሶስት አመት ያለፋት ሎሀን ለትወናው በመመረጧ ታላቅ ክብር እንደተሰማት ብትገልፅም አንዳንድ ታዋቂ ሰዎች ለኤልዛቤት ቴይለር ስብእና የማትመጥን ናት በሚል ተቃውሞ እያሰሙ ነው። በሙያው በቆየችባቸው አስር አመታት ከ በላይ ፊልሞች የተወነችው ሊንድሴይ ሎሀን በአለም ዙርያ  ሚሊዮን ዶላር ገቢ ያስገኘች ስትሆን በአንድ ፊልም  ሚሊዮን ዶላር አማካይ ገቢ እንዳላት የቦክስኦፊስ ባይ መረጃ ያመለክታል። \n",
      "===================\n",
      "Summarized\n",
      "\n",
      "\n",
      "ባለፉት ሶስት አመታት በአደንዛዥ እፅ ሱሰኝነት በቤተሰብ ችግርና በሌሎች የገንዘብ ኪሳራ እክሎች ስትባክን የቆየችው የ አመቷ ሊንድሴይ ሎሀን በአለም ዙርያ ሚሊዮን ዶላር አማካይ ገቢ እንዳላት የቦክስኦፊስ ባይ መረጃ ያመለክታል።\n"
     ]
    }
   ],
   "source": [
    "content = X_test.iloc[-20]\n",
    "title = y_test.iloc[-20]\n",
    "tparser = ExtractiveModel(content)\n",
    "article_summary = _get_summary(tparser)\n",
    "rouge_score(title, article_summary)\n",
    "print(\"\\n\\n\")\n",
    "print(\"Text\")\n",
    "print(\"\\n\")\n",
    "print(content)\n",
    "print(\"===================\")\n",
    "print(\"Summarized\")\n",
    "print(\"\\n\")\n",
    "print(article_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7cca3674-acd1-4913-b5f1-abde2f6cf34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.8051\n",
      "ROUGE-2: 0.7537\n",
      "ROUGE-L: 0.6214\n",
      "\n",
      "\n",
      "\n",
      "Original Summary\n",
      "\n",
      "\n",
      "\n",
      "የዓለም የምጣኔ ሃብት ጉባኤ ላይ ዶር ቴድሮስ መሥሪያ ቤታቸው ለመጪው ወረርሽኝ ከወዲሁ መሰናዶ መጀመሩን አብስረዋል። ይህ የወረርሽኝ ፈንድ እና የቴክኖሎጂ ልውውጥ ማዕከልን መክፈት ይጨምራል። ሌላው መጪው ዕቅድ ደግሞ በሃብታም እና ድሃ አገራት መሃል የክትባት ሥርጭትን ፍትሃዊ ማድረግ ነው። \n",
      "የአውሮፓ ኅብረት የበሽታ ቁጥጥር እና መከላከል ባለሥልጣናት በአውሮፓውያኑ ባወጣው አንድ ሪፖርት አዲስ የጤና መሠረተ ልማት ለመዘርጋት ከመሞከር ይልቅ ያለውን ማጠናከር ወረርሽኝን ቶሎ ለመግታት ይረዳል ብሎ ነበር። \n",
      "በ የዓለም ጤና ድርጅት ወረርሽኞች ሁልጊዜም ከሚታወቅ ምንጭ ይነሳሉ ብሎ አያምንም። አንዳንድ ጊዜ ለሰው ልጅ ግልጽ ባልሆኑ እና መኖራቸው እንኳ በማይታወቁ በሽታ አምጪ ተህዋስ ሊነሳ ይችላል። ለዚህ መፍትሄው ብዙ ሰዎች የክትባት ቴክኖሎጂን ማሳደግ እና ማዘመን ነው ዋናው ብለው ያምናሉ።\n",
      "\n",
      "===================\n",
      "\n",
      "\n",
      "Generated Summary\n",
      "\n",
      "\n",
      "የዓለም የምጣኔ ሃብት ጉባኤ ላይ ዶር ቴድሮስ መሥሪያ ቤታቸው ለመጪው ወረርሽኝ ከወዲሁ መሰናዶ መጀመሩን አብስረዋል። ይህ የወረርሽኝ ፈንድ እና የቴክኖሎጂ ልውውጥ ማዕከልን መክፈት ይጨምራል። ሌላው መጪው ዕቅድ ደግሞ በሃብታም እና ድሃ አገራት መሃል የክትባት ሥርጭትን ፍትሃዊ ማድረግ ነው። የአውሮፓ ኅብረት የበሽታ ቁጥጥር እና መከላከል ባለሥልጣናት በአውሮፓውያኑ ባወጣው አንድ ሪፖርት አዲስ የጤና መሠረተ ልማት ለመዘርጋት ከመሞከር ይልቅ ያለውን ማጠናከር ወረርሽኝን ቶሎ ለመግታት ይረዳል ብሎ ነበር። የሚዘረጉ መሠረተ ልማቶች እና የጤና ሥርዓቶች ወረርሽኝ ከመምጣቱ በፊት ሊፈተሹ ይገባልም ብሏል። በ የዓለም ጤና ድርጅት ወረርሽኞች ሁልጊዜም ከሚታወቅ ምንጭ ይነሳሉ ብሎ አያምንም። አንዳንድ ጊዜ ለሰው ልጅ ግልጽ ባልሆኑ እና መኖራቸው እንኳ በማይታወቁ በሽታ አምጪ ተህዋስ ሊነሳ ይችላል። ለዚህ መፍትሄው ብዙ ሰዎች የክትባት ቴክኖሎጂን ማሳደግ እና ማዘመን ነው ዋናው ብለው ያምናሉ። ወደፊት ሳይንቲስቶች ጊዜን ለመቆጠብ ከዚህ ቀደም ከተመረቱ ክትባቶች በአጭር ጊዜ የወረርሽ ሥርጭትን መግታት የሚቻለው አይበለውና በሽታ ኤክስ ወረርሽኝ ከተፈጠረ።\n"
     ]
    }
   ],
   "source": [
    "content = '''\n",
    "  የዓለም የምጣኔ ሃብት ጉባኤ በዳቮስ፣ ስዊትዘርላንድ ባለፈው ሳምንት ተካሂዷል። ጎን ለጎን የዓለም ጤና የሚያሳስባቸው ትልልቅ መሪዎች በር ዘግተው ለቀናት መክረዋል። እንደ ኮቪድ ያለ አዲስ ወረርሽኝ ከመምጣቱ በፊት ምን ይደረግ? እንዴት እንዘጋጅ በሚለው አጀንዳ ነው የተወያዩት።\n",
    "\n",
    "ለጊዜው መጪውን ወረርሽኝ ስሙን “በሽታ ኤክስ” በሚል ይዘውታል።\n",
    "\n",
    "የዓለም ጤና ድርጅት ከእንግዲህ መዘናጋት የለም፤ ለመጪው ወረርሽኝ መዘጋጀት የግድ ነው ሲል ነበር። ምክንያቱም የኮቪድ ወረርሽኝ ዓለም ላይ ያደረሰው ጠባሳ፣ አገራትን ያስከፈለው ዋጋ ቀደም ብሎ ዝግጅት ተደርጎ ቢሆን ኖሮ ይህን ያህል አይሆንም ነበር ይላሉ፤ ጤናውን ዘርፍ የሚመሩት።\n",
    "\n",
    "ዓለምን ትሪሊዮን ዶላር ያከሰራት ኮቪድ የሕክምና መሠረተ ልማት ከፍተኛ ደረጃ ደርሶ ቢሆን ኖሮ ውድመቱ ቢያንስ ይቀንስ ነበር ይላል የዓለም ጤና ድርጅት።\n",
    "\n",
    "“በሽታ-ኤክስ’’ ምንድነው?\n",
    "በሽታው በአሁኑ ወቅት በዓለም ላይ ያለ ሳይሆን፣ ወደፊት ሊመጣ ይችላል ተብሎ የሚገመት ወረርሽኝ ነው።\n",
    "\n",
    "ለዚያም ነው ቁርጥ ያለ ስም ሳይሰጠው በ”ኤክስ” ፊደል የተወከለው።\n",
    "\n",
    "ምናልባት ከአንድ አገር ተነስቶ አህጉር የሚያቋርጥ ሊሆን ይችላል። ወይም ደግሞ በተወሰኑ አገራት ጉዳት አድርሶ ሥርጭቱ ሊገታ የሚችል ይሆናል።\n",
    "\n",
    "ይህ ስያሜ ኮቪድ ከመምጣቱ በፊትም ነበር፣ ለነገሩ። የዓለም ጤና ድርጅት በአውሮፓውያኑ ጥር 2018 ስሙን ጠቀስ አድርጎት ነበር።\n",
    "\n",
    "በዓለም ጤና ድርጅት አንድ ክፍል አለ። ዋና ሥራው አዳዲስ ሊከሰቱ ለሚችሉ ወረርሽኞች ቀድሞ መዘጋጀት እና መሠረተ ልማቱን ማሰናዳት ነው።\n",
    "\n",
    "በወረርሽኝ ጊዜ ደግሞ ጥናትና ምርምር ማድረግ እና ለበሽታው የክትባት ሙከራዎችን ማድረግ፣ መድኃኒት መዘጋጀትን ይጨምራል። ዋንኛ ሥራው አንዳች ወረርሽኝ ሲከሰት ቶሎ ሥርጭቱን መግታት ነው።\n",
    "\n",
    "በቅርብ ዘመን ብዙ ወረርሽኞች ተቀስቅሰው ተመልክተናል።\n",
    "\n",
    "ሳርስ፣ ስዋይን ጉንፋን፣ ኢቦላ እና ኮቪድ የቅርብ ጊዜ ትዝታዎች ናቸው።\n",
    "\n",
    "የሚቀጥለው ዓለም አቀፍ ወረርሽን ምን ይሆን የሚለው ባለሙያዎችን ከወዲሁ ማወያየት የጀመረውም ለዚሁ ነው። የጤና ባለሙያዎች መጪው ወረርሽኝ ምናልባት ከእስከዛሬው ሁሉ የከፋ ይሆናል የሚል ፍርሃት አላቸው።\n",
    "\n",
    "\n",
    "“በሽታ ኤክስ’’ ወረርሽኝ ይሆናል?\n",
    "ባለፈው ሳምንት በነበረው የዓለም የምጣኔ ሃብት ጉባኤ ላይ አንድ ውይይት ተደርጎ ነበር።\n",
    "\n",
    "ውይይቱን የመሩት የዓለም ጤና ድርጅት ዳይሬክተር ዶ/ር ቴድሮስ አድሃኖም ገብረየሱስ ነበሩ።\n",
    "\n",
    "የውይይቱ ርዕስ “ለበሽታ ኤክስ መሰናዳት” ይሰኛል።\n",
    "\n",
    "ውይይቱ ያተኮረው ወደፊት ከኮቪድ የከፋ ወረርሽኝ ቢከሰት የጤና መዋቅሩ በቶሎ እንዲመክት እንዴት መዘጋጀት ይቻላል የሚል ነበር።\n",
    "\n",
    "ዶ/ር ቴድሮስ በውይይቱ ላይ ሲናገሩ “አንዳንድ ሰዎች በሽታው ገና ሳይከሰት ለገዳይ ወረርሽኝ መዘጋጀት ፍርሃትን ሊፈጥርባቸው ይችላል። ነገር ግን የሚያዋጣን በቂ ዝግጅት ማድረግ ነው፤ በሰው ልጅ ታሪክ ብዙ ወረርሽኞች ተከስተዋል፤ ወደፊትም ይከሰታሉ” ብለዋል።\n",
    "\n",
    "የኮቪድ ወረርሽኝ ብዙዎች የጠበቁት አልነበረም። ነገር ግን የወረርሽኝ ባለሙያዎች ይህ ነገር ቀድሞ ሊከሰት እንደሚችል ሲያስጠነቅቁ ነው የኖሩት።\n",
    "\n",
    "ከእነዚህ ባለሙያዎች መካከል ብዙዎቹ አሁንም ቀድሞ ከእንሰሳት የሚመነጭ ወረርሽኝ ያሰጋቸዋል።\n",
    "\n",
    "እስከ ዛሬ ከተከሰቱ ወረርሽኞች 75 በመቶዎቹ የሚሆኑት እንሰሳት ወለድ (zoonotic) ናቸው። በሌላ አነጋገር ከእንሰሳት ወደ ሰው የተላለፉ ናቸው።\n",
    "\n",
    "ኮቪድም እንደዚያ ነው። ቻይና ዉሃን ከሚገኝ የእንሰሳት እርድ ገበያ ወደ ሰው እንደተላለፈ ነው የሚገመተው። የሰው ልጆች ባህሪ፣ የአየር ንብረት መለወጥ፣ የሰው ልጆች ከቦታ ቦታ በፍጥነት መንቀሳቀስ፣ በዱር እንሰሳት አካባቢ የሰው ልጆች መገኘት እና ኑሯቸውን ማወክ እንሰሳት ወለድ ወረርሽ እንዲወለድ ሊያደርግ ይችላል ይላሉ ባለሙያዎች።\n",
    "\n",
    "የከተሞች መስፋፋት፣ የሕዝብ ብዛት በፍጥነት መጨመር፣ የንግድ መቀላጠፍ በተለይ ወረርሽኞች ሲነሱ በቀላሉ ዓለምን እንዲያዳርሱ ምቹ ሁኔታን ፈጥሯል ይላሉ ባለሙያዎች።\n",
    "\n",
    "\n",
    "ዓለም ለመጪው ወረርሽኝ ምን ያህል ተዘጋጅቷል?\n",
    "በዳቮስ የዓለም የምጣኔ ሃብት ጉባኤ ላይ ዶ/ር ቴድሮስ መሥሪያ ቤታቸው ለመጪው ወረርሽኝ ከወዲሁ መሰናዶ መጀመሩን አብስረዋል።\n",
    "\n",
    "ይህ የወረርሽኝ ፈንድ እና የቴክኖሎጂ ልውውጥ ማዕከልን መክፈት ይጨምራል። ሁለቱ ማዕከላት በደቡብ አፍሪካ ነው የተከፈቱት። አንዱ ዕቅድ በዚያው ማዕከል ክትባት እንዲመረት ማስቻል ነው። ሌላው መጪው ዕቅድ ደግሞ በሃብታም እና ድሃ አገራት መሃል የክትባት ሥርጭትን ፍትሃዊ ማድረግ ነው።\n",
    "\n",
    "በኮቪድ ጊዜ በዚህ ረገድ ብዙ ክፍተቶች እንደነበሩ ይታወሳል።\n",
    "\n",
    "የአውሮፓ ኅብረት የበሽታ ቁጥጥር እና መከላከል ባለሥልጣናት በአውሮፓውያኑ 2022 ባወጣው አንድ ሪፖርት፣ አዲስ የጤና መሠረተ ልማት ለመዘርጋት ከመሞከር ይልቅ ያለውን ማጠናከር ወረርሽኝን ቶሎ ለመግታት ይረዳል ብሎ ነበር።\n",
    "\n",
    "የሚዘረጉ መሠረተ ልማቶች እና የጤና ሥርዓቶች ወረርሽኝ ከመምጣቱ በፊት ሊፈተሹ ይገባልም ብሏል።\n",
    "\n",
    "በ2022 የዓለም ጤና ድርጅት 10 ምክረ ሐሳቦችን አሳትሞ ነበር። እነዚህ ምክረ ሐሳቦች በተፋጠነ ዘዴ የጤና መረጃን እንዴት መሰብሰብ እና መጋራት ይቻላል፤ እንዴትስ መተንተን ይቻላል የሚለውን ጉዳይ የሚያብራራ ነው።\n",
    "\n",
    "“የተሳለጠ የበሽታ ቅኝትና ክትትል ዘዴ (disease surveillance system) ወረርሽኝ ሲከሰት ቶሎ እንዲደረስበት ያስችላል። ወረርሽን ከተዛመተ በኋላ የብዙዎን ሕይወት ያሳጣል፤ ብዙ ዋጋ ያስከፍላል፤ መቆጣጠሩም ከአቅም በላይ ይሆናል” ይላል ከምክረ ሐሳቦች አንዱ።\n",
    "\n",
    "የዓለም ጤና ድርጅት ወረርሽኞች ሁልጊዜም ከሚታወቅ ምንጭ ይነሳሉ ብሎ አያምንም። አንዳንድ ጊዜ ለሰው ልጅ ግልጽ ባልሆኑ እና መኖራቸው እንኳ በማይታወቁ በሽታ አምጪ ተህዋስ (pathogen) ሊነሳ ይችላል።\n",
    "\n",
    "ለዚህ መፍትሄው ብዙ ሰዎች የክትባት ቴክኖሎጂን ማሳደግ እና ማዘመን ነው ዋናው ብለው ያምናሉ።\n",
    "\n",
    "በርካታ የኮቪድ ክትባቶች የተመረቱት ወረርሽኙ በተከሰተ በዓመቱ ነው። ይህ በሕክምና ታሪክ አስደናቂ የሚባል ነው።\n",
    "\n",
    "ወደፊት ሳይንቲስቶች ጊዜን ለመቆጠብ ከዚህ ቀደም ከተመረቱ ክትባቶች በአጭር ጊዜ አቀነባብሮ አዲስ ክትባት የሚፈጠርበትን መንገድ ሊያስቡ ይገባል። ልክ ምግብን ለማሰናዳት መሠረታዊ የሚባሉ አስቤዛዎች እንደሚያስፈልጉ ሁሉ ማለት ነው።\n",
    "\n",
    "ይህ ሲሆን ነው በአጭር ጊዜ የወረርሽ ሥርጭትን መግታት የሚቻለው፤ አይበለውና ‘በሽታ ኤክስ’ ወረርሽኝ ከተፈጠረ። አለዚያ ‘ወረርሽን ኤክስ’ በሚያደርሰው ጥፋት ኮቪድን የሚያስንቅ ሊሆን ይችላል።\n",
    "         '''\n",
    "\n",
    "title  = '''\n",
    "የዓለም የምጣኔ ሃብት ጉባኤ ላይ ዶር ቴድሮስ መሥሪያ ቤታቸው ለመጪው ወረርሽኝ ከወዲሁ መሰናዶ መጀመሩን አብስረዋል። ይህ የወረርሽኝ ፈንድ እና የቴክኖሎጂ ልውውጥ ማዕከልን መክፈት ይጨምራል። ሌላው መጪው ዕቅድ ደግሞ በሃብታም እና ድሃ አገራት መሃል የክትባት ሥርጭትን ፍትሃዊ ማድረግ ነው። \n",
    "የአውሮፓ ኅብረት የበሽታ ቁጥጥር እና መከላከል ባለሥልጣናት በአውሮፓውያኑ ባወጣው አንድ ሪፖርት አዲስ የጤና መሠረተ ልማት ለመዘርጋት ከመሞከር ይልቅ ያለውን ማጠናከር ወረርሽኝን ቶሎ ለመግታት ይረዳል ብሎ ነበር። \n",
    "በ የዓለም ጤና ድርጅት ወረርሽኞች ሁልጊዜም ከሚታወቅ ምንጭ ይነሳሉ ብሎ አያምንም። አንዳንድ ጊዜ ለሰው ልጅ ግልጽ ባልሆኑ እና መኖራቸው እንኳ በማይታወቁ በሽታ አምጪ ተህዋስ ሊነሳ ይችላል። ለዚህ መፍትሄው ብዙ ሰዎች የክትባት ቴክኖሎጂን ማሳደግ እና ማዘመን ነው ዋናው ብለው ያምናሉ።\n",
    "'''\n",
    "tparser = ExtractiveModel(content)\n",
    "article_summary = _get_summary(tparser)\n",
    "rouge_score(title, article_summary)\n",
    "print(\"\\n\\n\")\n",
    "print(\"Original Summary\")\n",
    "print(\"\\n\")\n",
    "print(title)\n",
    "print(\"===================\")\n",
    "print('\\n')\n",
    "print(\"Generated Summary\")\n",
    "print(\"\\n\")\n",
    "print(article_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef658cd8-be9b-4abd-bda3-6f56dafe9126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
